---
layout: post
title: OTA
author: [Jacques Wang]
category: [Lecture]
tags: [jekyll, ai]
---

Introduction to Edge-AI MCUs, TinyML, and examples.
## Project Review:
<iframe width="926" height="548" src="https://www.youtube.com/embed/si1-cgqFhTU" title="ESP32 IMU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
---
## Edge-AI MCU

### Kneron 耐能智慧
* KL530 AI SoC
![](https://www.kneron.com/tw/_upload/image/solution/large/938617699868711f.jpg)
  - 基於ARM Cortex M4 CPU内核的低功耗性能和高能效設計。
  - 算力達1 TOPS INT 4，在同等硬件條件下比INT 8的處理效率提升高達70%。
  - 支持CNN,Transformer，RNN Hybrid等多種AI模型。
  - 智能ISP可基於AI優化圖像質量，強力Codec實現高效率多媒體壓縮。
  - 冷啟動時間低於500ms，平均功耗低於500mW。
<br>
<br>
* KL720 AI SoC (算力可達0.9 TOPS/W)
![](https://www.kneron.com/tw/_upload/image/solution/large/95f4758c9cfd08.png)
  - 基於ARM Cortex M4 CPU内核的低功耗性能和高能效設計
  - 可適配高端IP攝像頭，智能電視，AI眼鏡、耳機以及AIoT網絡的終端設備。 
  - 可處理高達4K圖像，全高清影音和3D感應，實現精準的臉部識別以及手勢控制。 
  - 可為翻譯機和AI助手等產品提供自然語言處理。 
  - 以上各種功能以及其它邊緣AI — 例如感熱 — 均可實時處理。 
<br>

* [Kneron Launches KL530— Next Generation Auto-Grade AI Chip, Bringing L1 and L2 Autonomous Driving to Any Vehicle](https://www.kneron.com/en/news/blog/143/)<br>
![](https://www.kneron.com/_upload/custom/756244540e95de1.png)
![](https://www.kneron.com/_upload/custom/320624450cf5f035.png)
![](https://www.kneron.com/_upload/custom/49861835a540795c.png)
![](https://www.kneron.com/_upload/custom/60761835a85601d9.png)

* [Launching Kneron’s Next-Generation Chip KLM5S3, Pursuing Excellence in Edge-AI Computing](https://www.kneron.com/_upload/custom/216360e6ab1d06f.png)<br>
![](https://www.kneron.com/_upload/custom/216360e6ab1d06f.png)

---
### Realtek AmebaPro2
[AMB82-MINI](https://www.amebaiot.com/en/amebapro2/#rtk_amb82_mini)<br>
![](https://www.amebaiot.com/wp-content/uploads/2022/06/AMB82-MINI-2048x1489.jpg)
* MCU
  - Part Number: RTL8735B
  - 32-bit Arm v8M, up to 500MHz
* MEMORY
  - 768KB ROM
  - 512KB RAM
  - Supports MCM embedded DDR2/DDR3L memory up to 128MB
  - External Flash up to 64MB
* KEY FEATURES
  - Integrated 802.11 a/b/g/n Wi-Fi, 2.4GHz/5GHz
  - Bluetooth Low Energy (BLE) 4.2
  - Integrated Intelligent Engine @ 0.4 TOPS
  - Ethernet Interface
  - USB Host/Device
  - SD Host
  - ISP
  - Audio Codec
  - H.264/H.265
  - Secure Boot
  - Crypto Engine
* OTHER FEATURES
  - 2 SPI interfaces
  - 1 I2C interface
  - 8 PWM interfaces
  - 3 UART interfaces
  - 3 ADC interfaces
  - 2 GDMA interfaces
  - Max 23 GPIO
<iframe width="580" height="327" src="https://www.youtube.com/embed/_Kzqh6JXndo" title="AIoT: AmebaPro2 vs ESP32" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

---
## [mlplatform.org](https://www.mlplatform.org/)
The machine learning platform is part of the Linaro Artificial Intelligence Initiative and is the home for Arm NN and Compute Library – open-source software libraries that optimise the execution of machine learning (ML) workloads on Arm-based processors.
![](https://www.mlplatform.org/assets/images/assets/images/content/NN-frameworks20190814-800-1d11a6.webp)
<table>
  <tr><td>Project</td><td>Repository</td></tr>
  <tr><td>Arm NN</td><td>[https://github.com/ARM-software/armnn](https://github.com/ARM-software/armnn)</td></tr>
  <tr><td>Compute Library</td><td>[https://review.mlplatform.org/#/admin/projects/ml/ComputeLibrary](https://review.mlplatform.org/#/admin/projects/ml/ComputeLibrary)</td></tr>
  <tr><td>Arm Android NN Driver</td><td>https://github.com/ARM-software/android-nn-driver</td></tr>
</table>

---
### [ARM NN SDK](https://www.arm.com/zh-TW/products/silicon-ip-cpu/ethos/arm-nn)
免費提供的 Arm NN (類神經網路) SDK，是一組開放原始碼的 Linux 軟體工具，可在節能裝置上實現機器學習工作負載。這項推論引擎可做為橋樑，連接現有神經網路框架與節能的 Arm Cortex-A CPU、Arm Mali 繪圖處理器及 Ethos NPU。<br>

**[ARM NN](https://github.com/ARM-software/armnn)**<br>
Arm NN is the most performant machine learning (ML) inference engine for Android and Linux, accelerating ML on Arm Cortex-A CPUs and Arm Mali GPUs.

---
### ESP32
[ESP32-CAM Video Streaming and Face Recognition with Arduino IDE](https://randomnerdtutorials.com/esp32-cam-video-streaming-face-recognition-arduino-ide/)<br>
![](https://i0.wp.com/randomnerdtutorials.com/wp-content/uploads/2019/03/ESP32-CAM-getting-started.jpg?resize=1024%2C576&quality=100&strip=all&ssl=1)
![](https://github.com/rkuo2000/MCU-course/blob/main/images/Example_ESP32_MPU6050.jpg?raw=true)

---
## [TinyML](https://www.tinyml.org/)
[什麼是tinyML?](https://ithelp.ithome.com.tw/articles/10264226) Tiny Machine Learning<br>
TinyML 指能在微控制器上執行的機器學習 (一般機器學習模型需要AI加速器來執行）<br>
![](https://1.bp.blogspot.com/-XuWHULtnDgk/YULD2a9lvCI/AAAAAAAAEto/d45PphaZEYw5sI7W6M9vZ2d7lCw0cL9owCPcBGAYYCw/s1658/iThome_Day_02_Fig_01.jpg)

---
### Kaggle.com
人工智慧競賽的雲端平台, 提供免費的CPU / GPU / TPU<br>
* CPU: Intel  Xeon 2.0GHz, 1 core - 2 threads with 30GB RAM
* GPU: Nvidia Tesla P100-PCIE-16GB
![](https://tpucdn.com/gpu-specs/images/c/2888-front.small.jpg)
* GPU: T4 x2
* TPU: Google TPU v3-8 (8 cores)
![](https://storage.googleapis.com/kaggle-media/tpu/tpu_rule_of_thumb.png)

[Kaggle machine checkup](https://www.kaggle.com/code/rkuo2000/machine-checkup/notebook)<br>

---
### [Kaggle 用法簡介](https://rkuo2000.github.io/AI-course/lecture/2022/09/28/Kaggle-Introduction.html)

---
### [Easy-Net](https://www.kaggle.com/code/rkuo2000/easy-net)
用1個神經元可學習線性方程式 Y= 0.1*X + 0.3
![](https://github.com/rkuo2000/AI-course/blob/gh-pages/images/Easy-Net_architecture.png?raw=true)
```
model = models.Sequential()
model.add(layers.Dense(units=1, input_dim=1))
```
![](https://github.com/rkuo2000/AI-course/blob/gh-pages/images/Kaggle_Easy_Net_plot_prediction.png?raw=true)

---
### [Hidden-Net](https://www.kaggle.com/code/rkuo2000/hidden-net)
用10個神經元可學習拋物線方程式: Y = X^2 - 0.5
![](https://github.com/rkuo2000/AI-course/blob/gh-pages/images/Hidden-Net_architecture.png?raw=true)
```
model = models.Sequential()
model.add(layers.Dense(10, input_dim=1, activation='relu')) # add a hidden layer with 10 neurons 
model.add(layers.Dense(1, activation=None))
```
![](https://github.com/rkuo2000/AI-course/blob/gh-pages/images/Kaggle_Hidden_Net_plot_prediction.png?raw=true)

---
## ECG (Electrocardiogram)
![](https://www.msdmanuals.com/-/media/manual/home/images/c/v/s/cvs_ecg_reading.gif?mw=704&amp;thn=0&amp;sc_lang=en-sg)

---
### [ECG Heartbeat Categorization Dataset](https://www.kaggle.com/datasets/shayanfazeli/heartbeat)
This dataset is composed of two collections of heartbeat signals derived from two famous datasets in heartbeat classification, 
the [MIT-BIH Arrhythmia Dataset](https://www.physionet.org/content/mitdb/1.0.0/) and 
The [PTB Diagnostic ECG Database](https://www.physionet.org/content/ptbdb/1.0.0/).<br>
![](https://github.com/rkuo2000/MCU-course/blob/main/images/ECG_1beat.png?raw=true)
![](https://github.com/rkuo2000/MCU-course/blob/main/images/ECG_categories.png?raw=true)

[心電圖診斷理論基礎與系統](http://rportal.lib.ntnu.edu.tw:8080/server/api/core/bitstreams/9ae9fc6a-fa31-4bdf-b3ed-486881f61af8/content)<br>
ECG 心電圖分類：<br>
1. **Normal (正常心跳)**
2. **Artial Premature (早發性心房收縮)**
  - 早發性心房收縮就是心房在收到指令前提早跳動，由於打出的血量少而造成心跳空虛的症狀，再加上舒張期變長，回到心臟的血流增加使下一次的心跳力道較強，造成心悸的感覺，當心臟長期處於耗能異常的狀態，就容易併發心臟衰竭。
3. **Premature ventricular contraction (早發性心室收縮)**
  - 早發性心室收縮是心律不整的一種，是指病人的心室因為電位不穩定而提早跳動，病人會有心跳停格的感覺。因為病人心跳的質量差，心臟打出的血液量不足，卻仍會消耗能量，長期下來就可能衍生出心臟衰竭等嚴重疾病。早發性心室收縮的症狀包括心悸、頭暈、冷汗和胸悶等。
4. **Fusion of ventricular and normal (室性融合心跳)**
  - 室性融合波是由於兩個節律點發出的衝動同時激動心室的一部分形成的心室綜合波，是心律失常的干擾現象範疇
5. **Fusion of paced and normal (節律器融合心跳)**

---
### ECG DNN (Deep Neural Network)
**Kaggle:** [ECG-DNN](https://www.kaggle.com/code/rkuo2000/ecg-dnn)<br>

mitbih_train.csv 每一列(row) 為一筆心電圖資料(187個數值)<br>
x 為心電圖波形之數值, y 為心電圖波形之分類<br>

* 讀取資料 (訓練與測試 兩種資料集)
```
df_train = pd.read_csv("/kaggle/input/heartbeat/mitbih_train.csv", header=None)
df_test = pd.read_csv("/kaggle/input/heartbeat/mitbih_test.csv", header=None)
```
* 資料處理 
  - Y數值轉成以1位元代表一種分類（ECG資料有五種分類: 5-bit）
```
from tensorflow.keras import utils
y_train = utils.to_categorical(y_train)
y_test  = utils.to_categorical(y_test)
```

* 建立模型: 採用Tensorflow框架語法
```
from tensorflow.keras import models, layers
model = models.Sequential()
model.add(layers.InputLayer(input_shape=(187,)))
model.add(layers.Dense(128, activation="relu"))
model.add(layers.Dense(32,  activation="relu"))
model.add(layers.Dense(num_classes, activation="softmax"))
```

* 訓練模型: 輸入訓練資料集(x_train, y_train)與測試資料集(x_test, y_test)
```
hist = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test, y_test))
```

* 測試模型: 使用單筆測試資料進行辨識
```
pred = model.predict(X_test[0].reshape(-1, X_test[0].shape[0]))
print(pred)
print("predicted class =", np.argmax(pred))
```
[[9.9955231e-01 4.4117330e-04 4.7620933e-06 1.8245370e-06 3.4009862e-09]]<br>
predicted class = 0<br>
*輸出為一個陣列pred, 五個分類有五個可能概率 (1=100%, 9.9955231e-01 = 99.95%), 取最高可能概率為預測答案(0 = Normal正常心跳)*<br>

---
### [Arduino TinyML examples](https://github.com/rkuo2000/Arduino/tree/master/examples/TinyML)<br>

### Arduino Library: EloquentTinyML
![](https://github.com/rkuo2000/MCU-course/blob/main/images/Arduino_Library_EloquentTinyML.png?raw=true)

---
## TinyML ECG

### Kaggle TinyML-ECG
**Kaggle:** [TinyML-ECG](https://www.kaggle.com/code/rkuo2000/tinyml-ecg)<br>
* 從[Data](https://www.kaggle.com/code/rkuo2000/tinyml-ecg/data) 下載 **ecg_arrhythmia.h** 及 **x_test.h** 到 Arduino/examples/TinyML/TinyML_ECG/
* 重複執行export a test data之後的程式碼, 則可取得不同的測試資料 (x_test.h)
* 因82.8%測試資料為正常心跳([如圖](https://www.kaggle.com/code/rkuo2000/ecg-classification)), 可先執行[15]及[16], 看看波形
* 從print(y_test(idx))輸出可看出x_test.h 的Y值（心跳類別的可能概率)

---
### [TinyML_ECG.ino](https://github.com/rkuo2000/arduino/tree/master/examples/TinyML/TinyML_ECG)
* TinyML_ECG.ino (Arduino 程式碼)
* ecg_arrhythmia.h (TinyML轉出之可執行模型檔）
* x_test.h (隨機選出的單筆測試資料)

![](https://github.com/rkuo2000/MCU-course/blob/main/images/Sketch_TinyML_ECG.png?raw=true)
![](https://github.com/rkuo2000/MCU-course/blob/main/images/Sketch_TinyML_ECG_monitor.png?raw=true)

---
## TinyML AirDigit
1. **Arduino:** 
  - running MPU6050_ACC2CSV.ino to record motion into .csv (ex. 0_000.csv, ... 0_019.csv, 1_000.csv, ... 1_019.csv, 2_000.csv ... 2_019.csv)
2. **Kaggle:** 
  - upload .csv files to your Kaggle Datasets
  - modify [TinyML-AirDigit](https://www.kaggle.com/code/rkuo2000/tinyml-airdigit) to read your dataset
  - train TinyML-AirDigit to generate tinyml_airdigit.h & x_test.h
3. **Arduino:** 
  - run [TinyML_AirDigit.ino](https://github.com/rkuo2000/arduino/blob/master/examples/TinyML/TinyML_AirDigit/TinyML_AirDigit.ino) with tinyml_airdigit.h & x_test.h
  
### [MPU6050_ACC2CSV.ino](https://github.com/rkuo2000/arduino/tree/master/examples/IMU/MPU6050_ACC2CSV)
* 使用MPU6050每20毫秒讀取1次三軸加速器數值, 錄1.5秒動作 (1500ms / 20ms = 75筆accX, accY, accZ)
* Serial輸出為.csv格式, 由Serial-Monitor剪貼資料至.csv檔案
[2_000.csv](https://github.com/rkuo2000/arduino/blob/master/examples/IMU/MPU6050_ACC2CSV/2_000.csv)<br>

* 使用python程式[plot_acc2csv.py](https://github.com/rkuo2000/arduino/blob/master/examples/IMU/MPU6050_ACC2CSV/plot_acc2csv.py)來畫出三軸加速器變化圖 (PC須安裝Git-for-Window及Python3)<br>
`python3 plot_acc2csv.py 2_000.csv`<br>
![](https://github.com/rkuo2000/MCU-course/blob/main/images/Sketch_IMU_MPU6050_ACC2CSV_plot_acc2csv.png?raw=true)

---
### [TinyML_AirDigit.ino](https://github.com/rkuo2000/Arduino/tree/master/examples/TinyML/TinyML_AirDigit)
![](https://github.com/rkuo2000/MCU-course/blob/main/images/Sketch_TinyML_AirDigit.png?raw=true)



<br>
<br>

*This site was last updated {{ site.time | date: "%B %d, %Y" }}.*

